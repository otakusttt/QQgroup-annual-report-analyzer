# -*- coding: utf-8 -*-
import os
import re
import random
import string
import math
import jieba_fast as jieba
from collections import Counter, defaultdict
import config as cfg
from utils import (
    is_emoji,
    parse_timestamp,
    parse_datetime,
    clean_text,
    calculate_entropy,
    analyze_single_chars,
)
from logger import get_logger, init_logging

init_logging()

jieba.setLogLevel(jieba.logging.INFO)

logger = get_logger('analyzer')

_STOPWORDS_CACHE = None

_DIGIT_SYMBOL_PATTERN = re.compile(r'^[\d\W]+$')
_URL_PATTERN = re.compile(r'https?://')
_SENTENCE_SPLIT_PATTERN = re.compile(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰\s\n\r,\.!?\(\)]')

def load_stopwords(force_enable=None):
    """
    åŠ è½½åœç”¨è¯
    
    Args:
        force_enable: å¦‚æœä¸ºTrueï¼Œå¼ºåˆ¶åŠ è½½åœç”¨è¯ï¼›å¦‚æœä¸ºFalseï¼Œå¼ºåˆ¶ä¸åŠ è½½ï¼›å¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼
    """
    global _STOPWORDS_CACHE
    
    # å¦‚æœå¼ºåˆ¶ç¦ç”¨ï¼Œç›´æ¥è¿”å›ç©ºé›†åˆ
    if force_enable is False:
        return set()
    
    # å¦‚æœç¼“å­˜å·²å­˜åœ¨ä¸”ä¸æ˜¯å¼ºåˆ¶å¯ç”¨ï¼Œç›´æ¥è¿”å›ç¼“å­˜
    if _STOPWORDS_CACHE is not None and force_enable is not True:
        return _STOPWORDS_CACHE
    
    # å†³å®šæ˜¯å¦å¯ç”¨åœç”¨è¯
    if force_enable is True:
        use_stopwords = True
    else:
        # å®‰å…¨è·å–USE_STOPWORDSï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºFalse
        use_stopwords = getattr(cfg, 'USE_STOPWORDS', False)
    
    if not use_stopwords:
        logger.info("ğŸ“š åœç”¨è¯åŠŸèƒ½å·²ç¦ç”¨")
        _STOPWORDS_CACHE = set()
        return _STOPWORDS_CACHE
    
    stopwords = set()
    
    base_dir = os.path.dirname(__file__)
    # å®‰å…¨è·å–STOPWORDS_PATHSï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
    stopwords_paths = getattr(cfg, 'STOPWORDS_PATHS', [
        'resources/baidu_stopwords.txt',
        'backend/resources/baidu_stopwords.txt'
    ])
    candidate_paths = [os.path.join(base_dir, path) for path in stopwords_paths]
    
    stopwords_path = None
    for p in candidate_paths:
        if os.path.exists(p):
            stopwords_path = p
            break
    
    file_count = 0
    if stopwords_path:
        try:
            encoding = getattr(cfg, 'STOPWORDS_ENCODING', 'utf-8')
            with open(stopwords_path, 'r', encoding=encoding) as f:
                file_words = {line.strip() for line in f if line.strip() and not line.startswith('#')}
            stopwords.update(file_words)
            file_count = len(file_words)
            logger.info(f"ğŸ“š ä»æ–‡ä»¶åŠ è½½åœç”¨è¯ {file_count} ä¸ª (æ¥æº: {os.path.basename(stopwords_path)})")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½åœç”¨è¯æ–‡ä»¶å¤±è´¥: {e}")
    else:
        warn_if_missing = getattr(cfg, 'STOPWORDS_WARN_IF_MISSING', True)
        if warn_if_missing:
            logger.warning(f"âš ï¸  åœç”¨è¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è·¯å¾„: {candidate_paths}")
    
    manual_words = set(cfg.STOPWORDS_MANUAL) if hasattr(cfg, 'STOPWORDS_MANUAL') else set()
        
    stopwords.update(manual_words)
    manual_count = len(manual_words)
    
    total_count = len(stopwords)
    if manual_count > 0:
        logger.info(f"ğŸ“ æ‰‹åŠ¨æ·»åŠ åœç”¨è¯ {manual_count} ä¸ª")
    logger.info(f"âœ… åœç”¨è¯æ€»æ•°: {total_count} ä¸ª (æ–‡ä»¶: {file_count}, æ‰‹åŠ¨: {manual_count})")
    
    _STOPWORDS_CACHE = stopwords
    return _STOPWORDS_CACHE


class ChatAnalyzer:
    def __init__(self, data, use_stopwords=None):
        self.data = data
        self.messages = data.get('messages', [])
        self.chat_name = data.get('chatName', data.get('chatInfo', {}).get('name', 'æœªçŸ¥ç¾¤èŠ'))

        # å¦‚æœä¼ å…¥äº†use_stopwordså‚æ•°ï¼Œä½¿ç”¨ä¼ å…¥çš„å€¼ï¼›å¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼
        if use_stopwords is not None:
            self.use_stopwords = use_stopwords
        else:
            # å®‰å…¨è·å–USE_STOPWORDSï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºFalse
            self.use_stopwords = getattr(cfg, 'USE_STOPWORDS', False)
        
        # æ ¹æ®use_stopwordså‚æ•°å†³å®šæ˜¯å¦åŠ è½½åœç”¨è¯
        if self.use_stopwords:
            self.stopwords = load_stopwords(force_enable=True)
        else:
            self.stopwords = set()
        
        self._filter_messages_and_build_mappings()
        self.word_freq = Counter()
        self.word_samples = defaultdict(list)
        self.word_contributors = defaultdict(Counter)
        self.user_msg_count = Counter()
        self.user_char_count = Counter()
        self.user_char_per_msg = {}
        self.user_image_count = Counter()
        self.user_forward_count = Counter()
        self.user_reply_count = Counter()
        self.user_replied_count = Counter()
        self.user_at_count = Counter()
        self.user_ated_count = Counter()
        self.user_emoji_count = Counter()
        self.user_link_count = Counter()
        self.user_night_count = Counter()
        self.user_morning_count = Counter()
        self.user_repeat_count = Counter()
        self.hour_distribution = Counter()
        self.discovered_words = set()
        self.merged_words = {}
        self.single_char_stats = {}  
        self.cleaned_texts_with_sender = []  # æ”¹ä¸ºå­˜å‚¨ (æ–‡æœ¬, å‘é€è€…uin) å…ƒç»„

    
    def _filter_messages_and_build_mappings(self):
        """
        åˆå¹¶æ—¶é—´è¿‡æ»¤å’Œæ„å»º uin åˆ° name åŠ msgid_to_sender çš„æ˜ å°„ï¼Œ
        å‡å°‘ä¸¤æ¬¡éå†å¸¦æ¥çš„æ€§èƒ½å¼€é”€
        """
        # å®‰å…¨è·å–æ—¶é—´è¿‡æ»¤é…ç½®
        message_start_date = getattr(cfg, 'MESSAGE_START_DATE', None)
        message_end_date = getattr(cfg, 'MESSAGE_END_DATE', None)
        
        if message_start_date is None and message_end_date is None:
            filtered_messages = self.messages
        else:
            from datetime import datetime
            start_dt = None
            end_dt = None
            
            if message_start_date:
                try:
                    start_dt = datetime.strptime(message_start_date, '%Y-%m-%d')
                    start_dt = start_dt.replace(hour=0, minute=0, second=0, microsecond=0)
                    from datetime import timezone, timedelta
                    start_dt = start_dt.replace(tzinfo=timezone(timedelta(hours=8)))
                except Exception as e:
                    logger.warning(f"èµ·å§‹æ—¥æœŸæ ¼å¼é”™è¯¯: {message_start_date}, é”™è¯¯: {e}")
            
            if message_end_date:
                try:
                    end_dt = datetime.strptime(message_end_date, '%Y-%m-%d')
                    end_dt = end_dt.replace(hour=23, minute=59, second=59, microsecond=999999)
                    from datetime import timezone, timedelta
                    end_dt = end_dt.replace(tzinfo=timezone(timedelta(hours=8)))
                except Exception as e:
                    logger.warning(f"ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯: {message_end_date}, é”™è¯¯: {e}")
            
            filtered_messages = []
            for msg in self.messages:
                timestamp = msg.get('timestamp', '')
                msg_dt = parse_datetime(timestamp)
                if msg_dt is None:
                    continue
                if start_dt and msg_dt < start_dt:
                    continue
                if end_dt and msg_dt > end_dt:
                    continue
                filtered_messages.append(msg)
            
            filtered_count = len(filtered_messages)
            original_count = len(self.messages)
            if start_dt or end_dt:
                time_range = []
                if start_dt:
                    time_range.append(f"ä» {message_start_date}")
                if end_dt:
                    time_range.append(f"åˆ° {message_end_date}")
                logger.info(f"â° æ—¶é—´èŒƒå›´è¿‡æ»¤: {' '.join(time_range)}")
                logger.info(f"   åŸå§‹æ¶ˆæ¯: {original_count} æ¡, è¿‡æ»¤å: {filtered_count} æ¡")

        self.messages = filtered_messages
        
        uin_names = defaultdict(list)
        uin_member_names = {}
        msgid_to_sender = {}
        all_uins = set()

        for msg in self.messages:
            if self._is_bot_message(msg):
                continue
            sender = msg.get('sender', {})
            uin = sender.get('uin')
            name = (sender.get('name') or '').strip()
            msg_id = msg.get('messageId')
            if uin:
                all_uins.add(uin)
            if uin and name:
                if not uin_names[uin] or uin_names[uin][-1] != name:
                    uin_names[uin].append(name)
            if uin:
                raw_msg = msg.get('rawMessage', {})
                send_member_name = raw_msg.get('sendMemberName', '').strip()
                if send_member_name:
                    uin_member_names[uin] = send_member_name
            if msg_id and uin:
                msgid_to_sender[msg_id] = uin

        self.uin_to_name = {}
        for uin in all_uins:
            chosen_name = None
            
            # ä¼˜å…ˆä½¿ç”¨æœ‰æ•ˆçš„name
            if uin in uin_names:
                names = uin_names[uin]
                for name in reversed(names):
                    if name != str(uin):
                        chosen_name = name
                        break
                if chosen_name is None and names:
                    chosen_name = names[-1]
            
            # å…¶æ¬¡ä½¿ç”¨sendMemberName
            if chosen_name is None and uin in uin_member_names:
                chosen_name = uin_member_names[uin]
            
            # å…œåº•ï¼šä½¿ç”¨uinæœ¬èº«
            if chosen_name is None or chosen_name == str(uin):
                chosen_name = f"ç”¨æˆ·{uin}" 
            
            self.uin_to_name[uin] = chosen_name
        
        self.msgid_to_sender = msgid_to_sender

    def _is_bot_message(self, msg):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœºå™¨äººæ¶ˆæ¯ï¼ˆåŸºäº subMsgType æˆ– é…ç½®çš„æœºå™¨äººUINï¼‰"""
        # å®‰å…¨è·å–FILTER_BOT_MESSAGESï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºTrue
        filter_bot = getattr(cfg, 'FILTER_BOT_MESSAGES', True)
        if not filter_bot:
            return False
        
        raw_msg = msg.get('rawMessage', {})
        sub_msg_type = raw_msg.get('subMsgType', 0)
        if sub_msg_type in [577, 65]:
            return True
        
        # å®‰å…¨è·å–BOT_UINSï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºç©ºåˆ—è¡¨
        bot_uins = getattr(cfg, 'BOT_UINS', [])
        if bot_uins:
            sender_uin = msg.get('sender', {}).get('uin')
            if sender_uin and str(sender_uin) in [str(uin) for uin in bot_uins]:
                return True
        
        return False

    def get_name(self, uin):
        return self.uin_to_name.get(uin, f"æœªçŸ¥ç”¨æˆ·({uin})")

    def analyze(self):
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ: {self.chat_name}")
        logger.info(f"ğŸ“ æ¶ˆæ¯æ€»æ•°: {len(self.messages)}")

        logger.info("ğŸ§¹ ç¬¬ä¸€è½®ï¼šå¤„ç†æ¶ˆæ¯ï¼Œé¢„å¤„ç†æ–‡æœ¬ã€ç»Ÿè®¡è¯é¢‘å’Œè¶£å‘³æ•°æ®...")
        self._process_messages_once()

        logger.info("ğŸ”¤ åˆ†æå•å­—ç‹¬ç«‹æ€§...")
        self.single_char_stats = analyze_single_chars(
            [text for text, _ in self.cleaned_texts_with_sender]
        )

        logger.info("ğŸ” æ–°è¯å‘ç°...")
        discovered_count = self._discover_new_words()  

        logger.info("ğŸ”— è¯ç»„åˆå¹¶...")
        merged_count = self._merge_word_pairs()  

        if discovered_count > 0 or merged_count > 0:
            logger.info(f"ğŸ”„ å‘ç° {discovered_count} ä¸ªæ–°è¯ï¼Œåˆå¹¶ {merged_count} ä¸ªè¯ç»„")
            logger.info("ğŸ”„ é‡æ–°åˆ†è¯ä»¥åº”ç”¨æ–°è¯...")
            self._reprocess_word_frequency()
        
        logger.info("ğŸ§¹ é‡Šæ”¾ä¸´æ—¶å†…å­˜...")
        if self.cleaned_texts_with_sender:
            memory_mb = len(self.cleaned_texts_with_sender) * 100 / 1024 / 1024
            self.cleaned_texts_with_sender.clear()
            logger.debug(f"å·²é‡Šæ”¾çº¦ {memory_mb:.1f} MB å†…å­˜")

        logger.info("ğŸ§¹ è¿‡æ»¤æ•´ç†...")
        self._filter_results()

        logger.info("âœ… åˆ†æå®Œæˆ!")

    def _process_messages_once(self):
        """ä¸€æ¬¡éå†å®ç°é¢„å¤„ç†æ–‡æœ¬ã€è¯é¢‘ç»Ÿè®¡ã€è¶£å‘³ç»Ÿè®¡"""

        skipped = 0
        bot_filtered = 0
        prev_clean = None
        prev_sender = None

        for msg in self.messages:

            if self._is_bot_message(msg):
                continue
            
            sender_uin = msg.get('sender', {}).get('uin')
            if not sender_uin:
                continue

            if self._is_bot_message(msg):
                bot_filtered += 1
                continue
            
            sender_uin = msg.get('sender', {}).get('uin')
            if not sender_uin:
                continue
            
            content = msg.get('content', {})
            text = content.get('text', '') if isinstance(content, dict) else ''

            at_contents = []
            if '@' in text:
                elements = msg.get('rawMessage', {}).get('elements', [])
                for element in elements:
                    text_element = element.get('textElement')
                    if not text_element:
                        continue
                        
                    at_type = text_element.get('atType', 0)
                    content_text = text_element.get('content', '')
                    
                    if at_type == 2 and content_text:
                        at_contents.append(content_text)
                        
            cleaned = clean_text(text, at_contents)
            
            if cleaned and len(cleaned) >= 1:
                self.cleaned_texts_with_sender.append((cleaned, sender_uin))

                words = list(jieba.cut(cleaned))

                for word in words:
                    word = word.strip()
                    if not word:
                        continue
                    if self.use_stopwords and word in self.stopwords:
                        continue
                    
                    self.word_freq[word] += 1
                    if sender_uin:
                        self.word_contributors[word][sender_uin] += 1
                    sample_count = getattr(cfg, 'SAMPLE_COUNT', 10)
                    if len(self.word_samples[word]) < sample_count * 3:
                        self.word_samples[word].append(cleaned)

                self.user_msg_count[sender_uin] += 1
                self.user_char_count[sender_uin] += len(cleaned)
            else:
                if text:
                    skipped += 1

            raw = msg.get('rawMessage', {})
            elements = raw.get('elements', [])

            image_count = 0 
            emoji_count_from_elements = 0 
            has_forward = False
            has_link = False
            has_reply = False

            

            for elem in elements:
                elem_type = elem.get('elementType')
                
                if elem_type == 2:  # å›¾ç‰‡å…ƒç´ 
                    pic_elem = elem.get('picElement', {})
                    summary = pic_elem.get('summary', '')
                    # åˆ¤æ–­æ˜¯å¦ä¸ºè¡¨æƒ…åŒ…ï¼ˆsummaryæ ¼å¼ä¸º [è¡¨æƒ…åç§°]ï¼‰
                    if summary and summary.startswith('[') and summary.endswith(']'):
                        emoji_count_from_elements += 1
                    else:
                        image_count += 1
                
                elif elem_type == 1:  # æ–‡æœ¬å…ƒç´ 
                    text_elem = elem.get('textElement', {})
                    at_type = text_elem.get('atType', 0)
                    at_uid = text_elem.get('atUid', '')
                    at_uid_str = str(at_uid) if at_uid else ''
                    if at_type > 0 and at_uid_str and at_uid_str != '0' and at_uid_str != '':
                        self.user_at_count[sender_uin] += 1
                        self.user_ated_count[at_uid_str] += 1
                    
                    # é“¾æ¥ç»Ÿè®¡
                    text_content = text_elem.get('content', '')
                    if re.search(_URL_PATTERN, text_content):
                        has_link = True
                
                elif elem_type == 10:  # é“¾æ¥å…ƒç´ 
                    has_link = True
                
                elif elem_type == 16 and 'multiForwardMsgElement' in elem:  # åˆå¹¶è½¬å‘å…ƒç´ 
                    has_forward = True
                
                elif elem_type == 7:  # å›å¤å…ƒç´ 
                    has_reply = True
                    reply_elem = elem.get('replyElement', {})
                    
                    # ä¼˜å…ˆç”¨ senderUidï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    target_uin = reply_elem.get('senderUid')
                    
                    # å¦‚æœæ²¡æœ‰ï¼Œå›é€€åˆ°ç”¨ msgId æŸ¥æ‰¾
                    if not target_uin or target_uin == '0':
                        ref_msg_id = reply_elem.get('sourceMsgIdInRecords')
                        if not ref_msg_id or ref_msg_id == '0':
                            ref_msg_id = reply_elem.get('replayMsgId')
                        
                        if ref_msg_id and ref_msg_id != '0':
                            target_uin = self.msgid_to_sender.get(ref_msg_id)
                    
                    if target_uin and str(target_uin) != '0':
                        self.user_replied_count[str(target_uin)] += 1
            
            # ç»Ÿè®¡å„é¡¹æ•°æ®
            if image_count > 0:
                self.user_image_count[sender_uin] += image_count  
            
            if has_reply:
                self.user_reply_count[sender_uin] += 1
            
            if has_link:
                self.user_link_count[sender_uin] += 1
            
            if has_forward:
                self.user_forward_count[sender_uin] += 1    

            emojis = content.get('emojis', []) if isinstance(content, dict) else []
            emoji_count = len(emojis) + emoji_count_from_elements
            if emoji_count > 0:
                self.user_emoji_count[sender_uin] += emoji_count
            
            hour = parse_timestamp(msg.get('timestamp', ''))
            if hour is not None:
                self.hour_distribution[hour] += 1
                # å®‰å…¨è·å–æ—¶é—´èŒƒå›´é…ç½®
                night_owl_hours = getattr(cfg, 'NIGHT_OWL_HOURS', range(0, 6))
                early_bird_hours = getattr(cfg, 'EARLY_BIRD_HOURS', range(6, 9))
                if hour in night_owl_hours:
                    self.user_night_count[sender_uin] += 1
                if hour in early_bird_hours:
                    self.user_morning_count[sender_uin] += 1
            
            if cleaned and len(cleaned) >= 2:
                if cleaned == prev_clean and sender_uin != prev_sender:
                    self.user_repeat_count[sender_uin] += 1

            prev_clean = cleaned
            prev_sender = sender_uin
        
        # å¤„ç†è·³è¿‡åŠæœºå™¨äººæ¶ˆæ¯è®¡æ•°æ—¥å¿—
        if cfg.FILTER_BOT_MESSAGES and bot_filtered > 0:
            logger.debug(f"æœ‰æ•ˆæ–‡æœ¬: {len(self.cleaned_texts_with_sender)} æ¡, è·³è¿‡: {skipped} æ¡, è¿‡æ»¤æœºå™¨äºº: {bot_filtered} æ¡")
        else:
            logger.debug(f"æœ‰æ•ˆæ–‡æœ¬: {len(self.cleaned_texts_with_sender)} æ¡, è·³è¿‡: {skipped} æ¡")

        # è®¡ç®—äººå‡å­—æ•°ï¼ˆä¿ç•™1ä½å°æ•°ï¼‰
        for uin in self.user_msg_count:
            msg_count = self.user_msg_count[uin]
            char_count = self.user_char_count[uin]
            if msg_count >= 10:
                self.user_char_per_msg[uin] = round(char_count / msg_count, 1)

    def _discover_new_words(self):
        """æ–°è¯å‘ç°"""
        ngram_freq = Counter()
        left_neighbors = defaultdict(Counter)
        right_neighbors = defaultdict(Counter)
        total_chars = 0
        
        for text, _ in self.cleaned_texts_with_sender:
            sentences = re.split(_SENTENCE_SPLIT_PATTERN, text)
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 2:
                    continue
                total_chars += len(sentence)
                
                for n in range(2, min(6, len(sentence) + 1)):
                    for i in range(len(sentence) - n + 1):
                        ngram = sentence[i:i+n]
                        # åªè·³è¿‡çº¯ç©ºæ ¼
                        if not ngram.strip():
                            continue
                        ngram_freq[ngram] += 1
                        if i > 0:
                            left_neighbors[ngram][sentence[i-1]] += 1
                        else:
                            left_neighbors[ngram]['<BOS>'] += 1
                        if i + n < len(sentence):
                            right_neighbors[ngram][sentence[i+n]] += 1
                        else:
                            right_neighbors[ngram]['<EOS>'] += 1
        
        for word, freq in ngram_freq.items():
            if freq < cfg.NEW_WORD_MIN_FREQ:
                continue
            
            # é‚»æ¥ç†µ
            left_ent = calculate_entropy(left_neighbors[word])
            right_ent = calculate_entropy(right_neighbors[word])
            min_ent = min(left_ent, right_ent)
            if min_ent < cfg.ENTROPY_THRESHOLD:
                continue
            
            # PMI
            min_pmi = float('inf')
            for i in range(1, len(word)):
                left_freq = ngram_freq.get(word[:i], 0)
                right_freq = ngram_freq.get(word[i:], 0)
                if left_freq > 0 and right_freq > 0:
                    pmi = math.log2((freq * total_chars) / (left_freq * right_freq + 1e-10))
                    min_pmi = min(min_pmi, pmi)
            
            if min_pmi == float('inf'):
                min_pmi = 0
            
            if min_pmi < cfg.PMI_THRESHOLD:
                continue
            
            self.discovered_words.add(word)
        
        for word in self.discovered_words:
            jieba.add_word(word, freq=1000)
        
        discovered_count = len(self.discovered_words)

        logger.debug(f"å‘ç° {len(self.discovered_words)} ä¸ªæ–°è¯")

        return discovered_count

    def _merge_word_pairs(self):
        bigram_counter = Counter()
        word_right_counter = Counter()
        
        for text, _ in self.cleaned_texts_with_sender:
            words = [w for w in jieba.cut(text) if w.strip()]
            for i in range(len(words) - 1):
                w1, w2 = words[i].strip(), words[i+1].strip()
                if not w1 or not w2:
                    continue
                if re.match(_DIGIT_SYMBOL_PATTERN, w1) or re.match(_DIGIT_SYMBOL_PATTERN, w2):
                    continue
                bigram_counter[(w1, w2)] += 1
                word_right_counter[w1] += 1
        
        for (w1, w2), count in bigram_counter.items():
            merged = w1 + w2
            if len(merged) > cfg.MERGE_MAX_LEN:
                continue
            if count < cfg.MERGE_MIN_FREQ:
                continue
            
            # æ¡ä»¶æ¦‚ç‡ P(w2|w1)
            if word_right_counter[w1] > 0:
                prob = count / word_right_counter[w1]
                if prob >= cfg.MERGE_MIN_PROB:
                    self.merged_words[merged] = (w1, w2, count, prob)
                    jieba.add_word(merged, freq=count * 1000)

        merged_count = len(self.merged_words)
        
        logger.debug(f"åˆå¹¶ {len(self.merged_words)} ä¸ªè¯ç»„")
        
        if self.merged_words:
            sorted_merges = sorted(self.merged_words.items(), key=lambda x: -x[1][2])[:10]
            for merged, (w1, w2, cnt, prob) in sorted_merges:
                logger.debug(f"  {merged}: {w1}+{w2} ({cnt}æ¬¡, {prob:.0%})")
        
        return merged_count
    
    def _reprocess_word_frequency(self):
        # æ¸…ç©ºæ—§çš„è¯é¢‘ç»Ÿè®¡
        self.word_freq = Counter()
        self.word_samples = defaultdict(list)
        self.word_contributors = defaultdict(Counter)
        
        # é‡æ–°å¤„ç†æ¯æ¡æ¶ˆæ¯
        for cleaned, sender_uin in self.cleaned_texts_with_sender:
            # é‡æ–°åˆ†è¯
            words = list(jieba.cut(cleaned))
            
            for word in words:
                word = word.strip()
                if not word:
                    continue
                if self.use_stopwords and word in self.stopwords:
                    continue
                
                # é‡æ–°ç»Ÿè®¡
                self.word_freq[word] += 1
                if sender_uin:
                    self.word_contributors[word][sender_uin] += 1
                if len(self.word_samples[word]) < cfg.SAMPLE_COUNT * 3:
                    self.word_samples[word].append(cleaned)
        
        logger.debug(f"é‡æ–°åˆ†è¯å®Œæˆï¼Œå½“å‰è¯æ±‡æ€»æ•°: {len(self.word_freq)}")

    def _filter_results(self):
        """è¿‡æ»¤ç»“æœ"""
        filtered_freq = Counter()
        
        for word, freq in self.word_freq.items():
            if len(word) < cfg.MIN_WORD_LEN or len(word) > cfg.MAX_WORD_LEN:
                continue
            if freq < cfg.MIN_FREQ:
                continue
            if is_emoji(word):
                filtered_freq[word] = freq
                continue

            if word in cfg.WHITELIST:
                filtered_freq[word] = freq
                continue
            
            # å•å­—ç‰¹æ®Šå¤„ç†
            if len(word) == 1:
                # å•ä¸ªç¬¦å·è·³è¿‡ï¼ˆä½†æ•°å­—/å­—æ¯èµ°å•å­—ç»Ÿè®¡ï¼‰
                if word in string.punctuation or word in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€""''ï¼ˆï¼‰ã€ã€‘':
                    continue
                # å…¶ä»–å•å­—ï¼ˆæ•°å­—/å­—æ¯/æ±‰å­—ï¼‰èµ°ç‹¬ç«‹æ€§æ£€æŸ¥
                stats = self.single_char_stats.get(word)
                if stats:
                    total, indep, ratio = stats
                    if ratio < cfg.SINGLE_MIN_SOLO_RATIO or indep < cfg.SINGLE_MIN_SOLO_COUNT:
                        continue
                else:
                    continue
                        
            filtered_freq[word] = freq
        
        self.word_freq = filtered_freq
        
        # é‡‡æ ·
        for word in self.word_samples:
            samples = self.word_samples[word]
            sample_count = getattr(cfg, 'SAMPLE_COUNT', 10)
            if len(samples) > sample_count:
                self.word_samples[word] = random.sample(samples, sample_count)
        
        logger.debug(f"è¿‡æ»¤å {len(self.word_freq)} ä¸ªè¯")

    def get_top_words(self, n=None):
        n = n or cfg.TOP_N
        return self.word_freq.most_common(n)

    def get_word_detail(self, word):
        return {
            'word': word,
            'freq': self.word_freq.get(word, 0),
            'samples': self.word_samples.get(word, []),
            'contributors': [(self.get_name(uin), count) 
                           for uin, count in self.word_contributors[word].most_common(cfg.CONTRIBUTOR_TOP_N)]
        }

    def get_fun_rankings(self):
        rankings = {}
        
        def fmt(counter, top_n=cfg.RANK_TOP_N):
            return [(self.get_name(uin), count) for uin, count in counter.most_common(top_n)]
        
        rankings['è¯ç—¨æ¦œ'] = fmt(self.user_msg_count)
        rankings['å­—æ•°æ¦œ'] = fmt(self.user_char_count)
        
        sorted_avg = sorted(self.user_char_per_msg.items(), key=lambda x: x[1], reverse=True)[:cfg.RANK_TOP_N]
        rankings['é•¿æ–‡ç‹'] = [(self.get_name(uin), f"{avg:.1f}å­—/æ¡") for uin, avg in sorted_avg]
        
        rankings['å›¾ç‰‡ç‹‚é­”'] = fmt(self.user_image_count)
        rankings['åˆå¹¶è½¬å‘ç‹'] = fmt(self.user_forward_count)
        rankings['å›å¤ç‹‚'] = fmt(self.user_reply_count)
        rankings['è¢«å›å¤æœ€å¤š'] = fmt(self.user_replied_count)
        rankings['è‰¾ç‰¹ç‹‚'] = fmt(self.user_at_count)
        rankings['è¢«è‰¾ç‰¹æœ€å¤š'] = fmt(self.user_ated_count)
        rankings['è¡¨æƒ…å¸'] = fmt(self.user_emoji_count)
        rankings['é“¾æ¥åˆ†äº«ç‹'] = fmt(self.user_link_count)
        rankings['æ·±å¤œå…š'] = fmt(self.user_night_count)
        rankings['æ—©èµ·é¸Ÿ'] = fmt(self.user_morning_count)
        rankings['å¤è¯»æœº'] = fmt(self.user_repeat_count)
        
        return rankings
    
    def export_json(self):
        """å¯¼å‡ºJSONæ ¼å¼ç»“æœï¼ˆåŒ…å«uinä¿¡æ¯ï¼‰"""
        top_words = []
        for word, freq in self.get_top_words():
            # å†æ¬¡åœ¨å¯¼å‡ºé˜¶æ®µè¿‡æ»¤åœç”¨è¯ï¼Œä¿è¯æŠ¥å‘Šä¸­ä¸åŒ…å«åœç”¨è¯
            if self.use_stopwords and word in self.stopwords:
                continue
            top_words.append({
                'word': word,
                'freq': freq,
                'contributors': [
                    {
                        'name': self.get_name(uin),
                        'uin': uin,
                        'count': count
                    }
                    for uin, count in self.word_contributors[word].most_common(cfg.CONTRIBUTOR_TOP_N)
                ],
                'samples': self.word_samples.get(word, [])[:getattr(cfg, 'SAMPLE_COUNT', 10)]
            })

        result = {
            'chatName': self.chat_name,
            'messageCount': len(self.messages),
            'topWords': top_words,
            'rankings': {},
            'hourDistribution': {str(h): self.hour_distribution.get(h, 0) for h in range(24)}
        }
        
        # è¶£å‘³æ¦œå•ï¼ˆåŒ…å«uinï¼‰
        def fmt_with_uin(counter, top_n=cfg.RANK_TOP_N):
            return [
                {'name': self.get_name(uin), 'uin': uin, 'value': count}
                for uin, count in counter.most_common(top_n)
            ]
        
        result['rankings']['è¯ç—¨æ¦œ'] = fmt_with_uin(self.user_msg_count)
        result['rankings']['å­—æ•°æ¦œ'] = fmt_with_uin(self.user_char_count)
        
        # é•¿æ–‡ç‹ç‰¹æ®Šå¤„ç†
        sorted_avg = sorted(self.user_char_per_msg.items(), key=lambda x: x[1], reverse=True)[:cfg.RANK_TOP_N]
        result['rankings']['é•¿æ–‡ç‹'] = [
            {'name': self.get_name(uin), 'uin': uin, 'value': f"{avg:.1f}å­—/æ¡"}
            for uin, avg in sorted_avg
        ]
        
        result['rankings']['å›¾ç‰‡ç‹‚é­”'] = fmt_with_uin(self.user_image_count)
        result['rankings']['åˆå¹¶è½¬å‘ç‹'] = fmt_with_uin(self.user_forward_count)
        result['rankings']['å›å¤ç‹‚'] = fmt_with_uin(self.user_reply_count)
        result['rankings']['è¢«å›å¤æœ€å¤š'] = fmt_with_uin(self.user_replied_count)
        result['rankings']['è‰¾ç‰¹ç‹‚'] = fmt_with_uin(self.user_at_count)
        result['rankings']['è¢«è‰¾ç‰¹æœ€å¤š'] = fmt_with_uin(self.user_ated_count)
        result['rankings']['è¡¨æƒ…å¸'] = fmt_with_uin(self.user_emoji_count)
        result['rankings']['é“¾æ¥åˆ†äº«ç‹'] = fmt_with_uin(self.user_link_count)
        result['rankings']['æ·±å¤œå…š'] = fmt_with_uin(self.user_night_count)
        result['rankings']['æ—©èµ·é¸Ÿ'] = fmt_with_uin(self.user_morning_count)
        result['rankings']['å¤è¯»æœº'] = fmt_with_uin(self.user_repeat_count)
        
        return result
